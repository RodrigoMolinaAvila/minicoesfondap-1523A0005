{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se detallan las tareas que deben completar para la **Entrega Parcial 1**. Recuerden que el principal entregable es **predecir, con su mejor modelo, sobre los clientes del archivo `X_t1.parquet` y subir las predicciones a la plataforma CodaLab**. **Para esta entrega el desarrollo del informe es sugerido, pero no mandatorio**. Asegúrense de utilizar el archivo correspondiente para subir los resultados a la competencia. El uso de datos incorrectos se reflejará en un bajo desempeño en la tabla de clasificación.\n",
    "\n",
    "### **Tareas a realizar:**\n",
    "1. **Análisis exploratorio de datos:**  \n",
    "   Realicen un análisis detallado para identificar patrones, tendencias y relaciones en los datos. Este paso les permitirá comprender mejor las características del conjunto de datos y guiar las siguientes decisiones en el pipeline de modelamiento.\n",
    "\n",
    "2. **Preprocesamiento de datos:**  \n",
    "   Incluyan técnicas de preprocesamiento que aseguren la calidad y adecuación de los datos para los modelos. Algunas tareas sugeridas son:  \n",
    "   - Estandarización de filas y/o columnas.  \n",
    "   - Reducción de dimensionalidad.  \n",
    "   - Discretización de variables numéricas a categóricas.  \n",
    "   - Manejo de datos nulos.  \n",
    "   - Otras transformaciones relevantes según los datos disponibles.  \n",
    "\n",
    "3. **División del conjunto de datos:**  \n",
    "   Implementen una técnica **Hold-Out**, separando el conjunto de datos en **70% para entrenamiento** y **30% para testeo**.\n",
    "\n",
    "4. **Creación de un modelo baseline:**  \n",
    "   Entrenen un modelo sencillo que sirva como línea base para comparar el rendimiento de los modelos más avanzados.\n",
    "\n",
    "5. **Desarrollo de 3 modelos de Machine Learning diferentes al baseline:**  \n",
    "   - Utilicen exclusivamente pipelines de **Scikit-Learn** para esta iteración del proyecto.  \n",
    "   - El uso de librerías o herramientas externas será penalizado con una calificación de **0** en las secciones implicadas.  \n",
    "\n",
    "6. **Interpretabilidad del modelo con mejores resultados:**  \n",
    "   Apliquen técnicas que permitan interpretar y justificar los resultados obtenidos por el modelo con mejor desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Objetivos**\n",
    "\n",
    "En esta segunda parte, nos enfocaremos en profundizar y expandir nuestras capacidades de ML a través de las siguientes secciones clave:\n",
    "- Optimización de modelos\n",
    "- Interpretabilidad\n",
    "- Re-entrenamiento \n",
    "- Tracking\n",
    "- Despliegue\n",
    "\n",
    "NOTA: Los puntos desarrollados en esta entrega deben ser programados de forma funcional para facilitar su futura integración en un pipeline productivo con `Airflow`. No se espera la creación del pipeline en esta étapa, sin embargo, es crucial que el código esté preparado para su incorporación posterior.\n",
    "\n",
    "**<u>Recordatorio</u>: Para esta entrega sólo deben subir sus predicciones a CodaLab. El informe lo deberán subir en la tercera y última entrega.**\n",
    "\n",
    "## **Puntos a Desarrollar:**\n",
    "\n",
    "A continuación se describen las tareas a desarrollar en la presente fase.\n",
    "\n",
    "### **1. Optimización de modelos**\n",
    "\n",
    "A partir del análisis realizado en la primera entrega, deben desarrollar código para optimizar el performance de su modelo. Para esto, se espera que implementen técnicas de optimización de hiperparámetros vistas en clase (como `Optuna`) y de esta manera hacer mas eficiente el proceso de optimización. Recuerden optimizar hiperparámetros del modelo y de los pre procesadores utilizados (OneHot, Scalers, etc). Además, se espera que sean capaces de responder preguntas como:\n",
    "- ¿Qué métrica decidieron optimizar? ¿Porqué?\n",
    "- ¿Cuanto tiempo le destinaron a esta etapa? ¿Existen indicios de que resultados puedan mejorar destinando más tiempo?\n",
    "- ¿Qué hiperparámetro tuvo un mayor impacto en el performance de su modelo?\n",
    "\n",
    "### **2. Interpretabilidad**\n",
    "\n",
    "En esta sección ustedes deben ser capaces de explicar el funcionamiento de su modelo a través de las técnicas vistas en clases. A partir de sus resultados, deben ser capaces de responder preguntas como:\n",
    "- ¿Podría explicar el funcionamiento de su modelo para una predicción en particular? Si es así, explique 3 ejemplos.\n",
    "- ¿Qué atributo tiene una mayor importancia en la salida de su modelo? ¿Tiene esto sentido con el problema de negocio?\n",
    "- ¿Existe alguna interacción entre atributos que sea relevante para el modelo?\n",
    "- ¿Podría existir sesgo hacia algún atributo en particular? ¿Cuál?\n",
    "\n",
    "### **3. Re-entrenamiento de  Modelos**\n",
    "\n",
    "Con la variación y entrega de nuevos datos, un proyecto de data-science debe incluir este paso. Sin embargo, entrenar con todos los datos puede ser costoso. Es importante comprender que un re-entrenamiento puede ser caro y requiere herramientas adecuadas. Como primera aproximación a este paradigma, se les pide lo siguiente:\n",
    "\n",
    "- Diseñar y ejecutar estrategias de re-entrenamiento para mantener la precisión y relevancia de los modelos, utilizando estrategias de partial fit.\n",
    "- Automatizar el proceso de actualización de modelos basados en nuevos datos y feedback recibido a través de una función.\n",
    "- Acompañar el re-entrenamiento de una etapa de optimización.\n",
    "\n",
    "Podría serles útil la inicialización de modelos en base a pesos pasados. Mayor información la pueden encontrar en el siguiente [link](https://stackoverflow.com/questions/38079853/how-can-i-implement-incremental-training-for-xgboost).\n",
    "\n",
    "### 4. Tracking con MLFlow:\n",
    "Durante el modelamiento suceden muchas cosas, por lo que es relevante hacer un tracking de todos los elementos generados por el modelo: métricas de desempeño, modelo, hiperparámetros, importancia de optimización, interpretabilidad, etc.\n",
    "\n",
    "- Configurar MLFlow para rastrear experimentos, entrenamientos y versiones de modelos.\n",
    "- Generar el tracking de los pasos más relevantes del modelo.\n",
    "\n",
    "### 5. Creación de una aplicación web con Gradio y FastAPI:\n",
    "Nuestro objetivo es entregar este producto a un cliente final, por lo que debe ser fácilmente consultable a través de una aplicación. Una buena alternativa es la creación de una aplicación web a través de Gradio y FastAPI. En particular, se les pide:\n",
    "\n",
    "- Desarrollar el frontend en Gradio. El front debe ser amigable y permitir al usuario realizar predicciones de manera sencilla e intuitiva.\n",
    "- Desarrollar el backend en FastAPI con la lógica de inferencia del modelo. \n",
    "- La aplicación web debe aceptar la carga de datos a través de un archivo plano .csv y la inputación manual de los datos a predecir en un formulario (a la hora de la predicción, ambas vías deben estar habilitadas pero el usuario debe escoger sólo un método).\n",
    "- El backend y el frontend deben comunicarse para la generación de predicciones.\n",
    "- Tanto el backend como el frontend deben estar dockerizados. Con esto, aseguramos la escalabilidad, portabilidad y despliegue eficiente de la aplicación web en diferentes entornos.\n",
    "\n",
    "Para la utilización de Docker, les podría ser de utilidad la [cheatsheet](https://dockerlabs.collabnix.com/docker/cheatsheet/) de dockerlabs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estructura del Informe\n",
    "\n",
    "De acuerdo con lo señalado en entregas previas, el equipo debe presentar un informe siguiendo la estructura detallada a continuación:\n",
    "\n",
    "## **1. Introducción [0.25 puntos]**\n",
    "\n",
    "Esta sección debe incluir:  \n",
    "- Una descripción breve del problema planteado: ¿Qué se busca predecir?  \n",
    "- Un resumen de los datos de entrada proporcionados.  \n",
    "- La métrica seleccionada para evaluar los modelos, con su respectiva justificación. Dado que los datos están desbalanceados, se recomienda evitar el uso de `accuracy` y centrarse en métricas como `precision`, `recall` o `f1-score`, especificando la clase de interés.  \n",
    "- Una mención breve de los modelos empleados para abordar el problema, incluyendo las transformaciones intermedias aplicadas a los datos.  \n",
    "- Un análisis general de los resultados obtenidos, señalando si el modelo final cumplió con los objetivos planteados y cómo se posicionó frente a los de otros equipos.\n",
    "\n",
    "## **2. Preprocesamiento [0.75 puntos]**\n",
    "\n",
    "### **2.1 Análisis Exploratorio de Datos [0.5 puntos]**\n",
    "\n",
    "Se debe realizar un análisis detallado para identificar patrones, tendencias y relaciones en los datos. Este análisis permitirá una mejor comprensión de las características del conjunto de datos y guiará las decisiones en el pipeline de modelamiento.\n",
    "\n",
    "Se deben incluir:  \n",
    "- Estadísticas descriptivas generales.  \n",
    "- Visualizaciones para detectar distribuciones, valores atípicos y relaciones entre variables.  \n",
    "- Observaciones relevantes que puedan influir en las etapas posteriores del proyecto.  \n",
    "\n",
    "El análisis debe presentarse de manera profesional, demostrando tanto la implementación técnica como una comprensión profunda del problema y los datos.\n",
    "\n",
    "### **2.2 Preprocesamiento de Datos [0.25 puntos]**\n",
    "\n",
    "Se deben aplicar técnicas de preprocesamiento que garanticen la calidad y adecuación de los datos para el modelamiento. Algunas tareas recomendadas son:  \n",
    "- Estandarización de filas y/o columnas.  \n",
    "- Reducción de dimensionalidad.  \n",
    "- Discretización de variables numéricas a categóricas.  \n",
    "- Manejo de valores nulos.  \n",
    "- Otras transformaciones pertinentes según las características del conjunto de datos.  \n",
    "\n",
    "Esta sección debe enfocarse en la limpieza y preparación de los datos para su uso en el entrenamiento y evaluación de los modelos. Es fundamental realizar un **`train_test_split`** para dividir los datos en conjuntos de entrenamiento y validación siguiendo una proporción adecuada (por ejemplo, 70/30).\n",
    "\n",
    "Se espera implementar las siguientes técnicas:  \n",
    "- **Uso de `ColumnTransformer`:** Aplicar transformaciones específicas a distintas columnas.  \n",
    "- **Imputación de valores nulos:** Seleccionar una estrategia apropiada (media, mediana, moda, etc.) para completar datos faltantes.  \n",
    "- **Discretización de variables:** Convertir variables continuas en categóricas cuando sea beneficioso para el modelo.  \n",
    "- **Estandarización o normalización:** Mejorar el rendimiento de algoritmos sensibles a la escala de los datos.  \n",
    "- Otras transformaciones relevantes en función de las características de los datos.\n",
    "\n",
    "Se deben documentar y justificar cada decisión en el informe, vinculando las elecciones con los objetivos del proyecto.\n",
    "\n",
    "## **3. Modelamiento [1.75 puntos]**\n",
    "\n",
    "### **3.1 Baseline [0.25 puntos]**\n",
    "\n",
    "Se debe implementar una técnica **Hold-Out**, dividiendo los datos en **70% para entrenamiento** y **30% para prueba**.\n",
    "\n",
    "**Creación de un modelo baseline:**  \n",
    "El equipo debe entrenar un modelo básico que sirva como referencia para evaluar los modelos más avanzados.\n",
    "\n",
    "Esta sección requiere construir el modelo más sencillo posible, conocido como **modelo baseline**, que servirá como punto de referencia para comparar el rendimiento de los modelos posteriores.  \n",
    "\n",
    "Pasos requeridos:  \n",
    "- Implementar, entrenar y evaluar un modelo básico utilizando un pipeline.  \n",
    "- Incluir en el pipeline las transformaciones realizadas previamente junto con un clasificador básico.  \n",
    "- Evaluar el modelo utilizando **`classification_report`** y documentar las métricas obtenidas.  \n",
    "\n",
    "Es necesario documentar claramente cómo se creó el modelo, las decisiones tomadas y los resultados, ya que este será la base comparativa.\n",
    "\n",
    "### **3.2 Modelos de Machine Learning [0.5 puntos]**\n",
    "\n",
    "- Se deben utilizar exclusivamente pipelines de **Scikit-Learn** para esta iteración del proyecto.  \n",
    "- El uso de librerías o herramientas externas será penalizado con una calificación de **0** en las secciones implicadas.  \n",
    "\n",
    "Se deben desarrollar tres modelos avanzados, cada uno integrado en un pipeline que combine el preprocesamiento con un clasificador.  \n",
    "\n",
    "Se debe incluir:  \n",
    "- **Estructura y diferencias:** Describir los clasificadores seleccionados, sus hiperparámetros iniciales y el enfoque adoptado.  \n",
    "- **Resultados:** Evaluar cada modelo utilizando **`classification_report`**, destacando métricas como precisión, recall y f1-score.  \n",
    "- **Clasificadores sugeridos:**  \n",
    "  - `LogisticRegression`  \n",
    "  - `KNeighborsClassifier`  \n",
    "  - `DecisionTreeClassifier`  \n",
    "  - `SVC`  \n",
    "  - `RandomForestClassifier`  \n",
    "  - `LightGBMClassifier` (`lightgbm`)  \n",
    "  - `XGBClassifier` (`xgboost`)  \n",
    "  - Otros.  \n",
    "\n",
    "Se deben responder las siguientes preguntas:  \n",
    "1. ¿Algún clasificador supera al modelo baseline?  \n",
    "2. ¿Cuál es el mejor clasificador entrenado y por qué?  \n",
    "3. ¿Qué factores explican la superioridad del mejor clasificador?  \n",
    "4. ¿Qué modelo es más eficiente para realizar optimizaciones en términos de tiempo de entrenamiento?  \n",
    "\n",
    "Finalmente, se debe seleccionar **uno de los tres modelos** para las siguientes secciones y justificar su elección.\n",
    "\n",
    "### **3.3 Optimización de Modelos [0.5 puntos]**\n",
    "\n",
    "Se debe optimizar el modelo seleccionado implementando técnicas de ajuste de hiperparámetros, como `Optuna`.  \n",
    "\n",
    "Se deben responder:  \n",
    "- ¿Qué métrica se decidió optimizar y por qué?  \n",
    "- ¿Cuánto tiempo se dedicó a esta etapa? ¿Podrían lograrse mejores resultados invirtiendo más tiempo?  \n",
    "- ¿Qué hiperparámetro tuvo mayor impacto en el rendimiento del modelo?  \n",
    "\n",
    "Se deben incluir mejoras como selección de atributos o ajustes en el imputador de datos y explicar cómo estas decisiones influyen en el rendimiento.\n",
    "\n",
    "### **3.4 Interpretabilidad [0.5 puntos]**\n",
    "\n",
    "Se debe explicar el funcionamiento del modelo utilizando herramientas de interpretabilidad como `SHAP` o `Anchors`.  \n",
    "\n",
    "Se debe incluir:  \n",
    "- Justificaciones para tres predicciones concretas.  \n",
    "- Identificación del atributo más relevante para las predicciones y su relación con el problema.  \n",
    "- Posibles sesgos hacia atributos específicos y su mitigación.  \n",
    "\n",
    "El informe debe demostrar cómo estas herramientas permiten interpretar los resultados del modelo y tomar decisiones fundamentadas.\n",
    "\n",
    "## **4. MLOps [2.5 puntos]**\n",
    "\n",
    "### **4.1 Tracking con MLFlow [0.6 puntos]**\n",
    "\n",
    "Durante el proceso de modelamiento, se debe realizar un seguimiento detallado de los elementos generados, incluyendo métricas de desempeño, modelos, hiperparámetros, optimización, interpretabilidad, entre otros.\n",
    "\n",
    "Requisitos:  \n",
    "- Configurar MLFlow para rastrear experimentos, entrenamientos y versiones de los modelos.  \n",
    "- Documentar el seguimiento de los pasos clave del pipeline.  \n",
    "\n",
    "Se deben presentar los resultados del tracking implementado, destacando elementos como métricas de desempeño, hiperparámetros utilizados y análisis de optimización.  \n",
    "Para guiarse, se puede consultar el [quickstart guide de MLFlow](https://mlflow.org/docs/latest/tracking.html#quickstart).\n",
    "\n",
    "**Nota:** Se deben asignar nombres descriptivos a los experimentos para facilitar su identificación y análisis.\n",
    "\n",
    "### **4.2 Desarrollo de Aplicación Web [0.6 puntos]**\n",
    "\n",
    "El equipo debe desarrollar una aplicación web que facilite la consulta del producto final por parte del cliente. Para ello, se deben cumplir los siguientes requisitos:\n",
    "\n",
    "- **Frontend con Gradio:** Crear una interfaz amigable e intuitiva para realizar predicciones.  \n",
    "- **Backend con FastAPI:** Implementar la lógica de inferencia del modelo en el backend.  \n",
    "- **Entrada de datos:**  \n",
    "  - La aplicación debe permitir dos métodos de entrada:  \n",
    "    1. Carga de un archivo `.csv`.  \n",
    "    2. Ingreso manual mediante un formulario.  \n",
    "  - Ambos métodos deben estar habilitados, pero el usuario deberá elegir uno para realizar la predicción.  \n",
    "- **Dockerización:** Tanto el backend como el frontend deben estar dockerizados para garantizar portabilidad, escalabilidad y despliegue eficiente en diferentes entornos.\n",
    "\n",
    "El equipo debe asegurar que la comunicación entre backend y frontend permita una experiencia fluida para el usuario.  \n",
    "Para guiarse, pueden consultar la [cheatsheet de DockerLabs](https://dockerlabs.collabnix.com/docker/cheatsheet/).\n",
    "\n",
    "### **4.3 Monitoreo [0.3 puntos]**\n",
    "\n",
    "El equipo debe implementar un sistema de monitoreo para garantizar la consistencia de los datos y el desempeño del modelo en producción. Esto incluye:\n",
    "\n",
    "- **Data drift:** Desarrollar un método para detectar diferencias significativas entre los nuevos datos y los datos originales.  \n",
    "- **Evaluación continua:** Supervisar el rendimiento del modelo en producción para identificar desviaciones y anomalías.\n",
    "\n",
    "Se deben responder las siguientes preguntas:  \n",
    "- ¿Se detecta data drift? ¿Cómo se abordará?  \n",
    "- ¿Qué sucede si los datos nuevos son más desbalanceados?  \n",
    "\n",
    "Además, se deben justificar las decisiones tomadas para manejar estas situaciones.\n",
    "\n",
    "### **4.4 Canalizaciones Productivas [1.0 puntos]**\n",
    "\n",
    "El equipo debe diseñar e implementar una canalización productiva utilizando **Apache Airflow** para automatizar y optimizar el flujo de trabajo. Esta canalización debe incluir:\n",
    "\n",
    "1. **Extracción de datos:** Recolectar datos desde las fuentes definidas (por ejemplo, GitLab).  \n",
    "2. **Limpieza y transformación:** Garantizar la calidad y consistencia de los datos.  \n",
    "3. **Análisis de data drift:** Comparar los datos nuevos con el conjunto original para detectar desviaciones significativas.  \n",
    "4. **Reentrenamiento del modelo:** Activar automáticamente el reentrenamiento si se detecta data drift.  \n",
    "5. **Tracking de interpretabilidad:** Registrar y guardar figuras generadas por herramientas como SHAP.\n",
    "\n",
    "El equipo debe integrar las siguientes librerías: **Apache Airflow**, **Optuna**, **SHAP** y **MLFlow**.  \n",
    "Se debe presentar:\n",
    "\n",
    "- Una descripción del **DAG** del pipeline, explicando la funcionalidad de cada tarea y la relación entre ellas.  \n",
    "- Una representación visual del **DAG** con ejemplos de ejecución para distintas fechas.  \n",
    "- Una explicación de los beneficios de una canalización atomizada e idempotente.  \n",
    "\n",
    "## **5. Resultados [0.5 puntos]**\n",
    "\n",
    "El equipo debe documentar los resultados obtenidos a lo largo de las iteraciones del proyecto, considerando que habrá al menos tres ciclos de entrenamiento. Se debe analizar cómo cambiaron los resultados a medida que se ajustaron los modelos y estrategias.\n",
    "\n",
    "Preguntas a responder:  \n",
    "- ¿Cuál fue el rendimiento de los modelos para abordar el problema?  \n",
    "- ¿Qué significan estos resultados en términos prácticos?  \n",
    "- ¿Cómo evolucionaron los resultados a lo largo de las iteraciones?  \n",
    "- ¿Qué fenómenos o hiperparámetros podrían explicar gran parte de los resultados obtenidos?  \n",
    "- ¿Qué factores contribuyeron al overfitting o underfitting y cómo influyeron en la elección del mejor modelo?\n",
    "\n",
    "El análisis debe ser exhaustivo, explicando los resultados desde un punto de vista técnico y metodológico.\n",
    "\n",
    "## **6. Conclusiones [0.25 puntos]**\n",
    "\n",
    "El equipo debe sintetizar los hallazgos del proyecto, conectando todas las secciones del informe desde la Introducción hasta los Resultados. Las conclusiones deben incluir:\n",
    "\n",
    "- Identificación de los modelos con mejor desempeño.  \n",
    "- Observaciones generales sobre los datos y la problemática.  \n",
    "- Reflexiones sobre las herramientas y técnicas utilizadas, destacando su utilidad y limitaciones.  \n",
    "\n",
    "El cierre debe proporcionar una visión global del proyecto, destacando las decisiones clave tomadas durante su desarrollo y su impacto en los resultados obtenidos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
