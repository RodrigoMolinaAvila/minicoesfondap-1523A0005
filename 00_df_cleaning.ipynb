{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustes DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsear_fecha(fecha):\n",
    "    try:\n",
    "        return pd.to_datetime(fecha, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        try:\n",
    "            return pd.to_datetime(fecha, format=\"%d-%m-%Y\")\n",
    "        except:\n",
    "            return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FechaPublicacion\"] = df[\"FechaPublicación\"].apply(parsear_fecha)\n",
    "df[\"Año\"] = df[\"FechaPublicacion\"].dt.year\n",
    "df[\"Mes\"] = df[\"FechaPublicacion\"].dt.month\n",
    "df[\"Dia\"] = df[\"FechaPublicacion\"].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"FechaPublicación\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenación de las variables con texto informativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Título\"] = df[\"Título\"].fillna(\"\")\n",
    "df[\"Corpus\"] = df[\"Corpus\"].fillna(\"\")\n",
    "df[\"CorpusPDF\"] = df[\"CorpusPDF\"].fillna(\"\")\n",
    "df[\"Texto\"] = df[\"Título\"] + \". \" + df[\"Corpus\"] + \". \" + df[\"CorpusPDF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de limpieza texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stopwords = file.read().splitlines()\n",
    "    return [word.lower() for word in stopwords if word.strip()]\n",
    "\n",
    "stopwords_list = load_stopwords(\"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    text = re.sub(r\"[0-9]\", \" \", text)\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_unprintable_(text):\n",
    "    printable = set(string.printable + \"ñáéíóúü\" + \"ÑÁÉÍÓÚÜ\")\n",
    "    text = \"\".join(filter(lambda x: x in printable, text))\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    pattern = re.compile(r\"[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]\")\n",
    "    t = pattern.sub(r\" \", text)\n",
    "    return re.sub(\" +\", \" \", t)\n",
    "\n",
    "def reduce_spam(text):\n",
    "    text = re.sub(r\"(\\w+)(\\s+\\1){2,}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"(\\w+\\s+\\w+)(\\s+\\1){2,}\", r\"\\1\", text)\n",
    "    return text\n",
    "\n",
    "def remove_vowels_accents(text):\n",
    "    return (\n",
    "        text.replace(\"á\", \"a\")\n",
    "        .replace(\"é\", \"e\")\n",
    "        .replace(\"í\", \"i\")\n",
    "        .replace(\"ó\", \"o\")\n",
    "        .replace(\"ú\", \"u\")\n",
    "        .replace(\"ü\", \"u\")\n",
    "    )\n",
    "\n",
    "def remove_stopwords(text, stopwords_list):\n",
    "    return \" \".join(\n",
    "        [word for word in str(text).split() if word not in stopwords_list]\n",
    "    )\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_unprintable_(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = reduce_spam(text)\n",
    "    text = remove_stopwords(text, stopwords_list)\n",
    "    text = remove_vowels_accents(text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se aplica la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TextoLimpio\"] = df[\"Texto\"].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Texto\", \"FechaPublicación2\", \"CorpusPDF\", \"EnlacePDF\", \"año\", \"Corpus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se exporta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"Database/01_bbdd_think_tanks.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Database/01_bbdd_think_tanks.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
