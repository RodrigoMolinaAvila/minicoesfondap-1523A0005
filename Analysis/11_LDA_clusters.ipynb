{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c297aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc85da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e76d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"01_bbdd_think_tanks_no_stopwords.parquet\" , engine=\"fastparquet\")\n",
    "df = df[(df[\"FechaPublicacion\"] >= \"2019-01-01\") & (df[\"FechaPublicacion\"] <= \"2023-12-31\")]\n",
    "df[\"Dia\"] = df[\"FechaPublicacion\"].dt.to_period(\"D\")\n",
    "\n",
    "with open(\"stopwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords_custom = set(line.strip().lower() for line in f if line.strip())\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^a-zA-ZáéíóúüñÁÉÍÓÚÜÑ\\s]\", \"\", text.lower())\n",
    "    return [w for w in text.split() if len(w) > 2 and w not in stopwords_custom]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4e9afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17432 entries, 205 to 31640\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ID                    17432 non-null  int64         \n",
      " 1   Think Tank            17432 non-null  object        \n",
      " 2   Tipo de Think Tank    17432 non-null  object        \n",
      " 3   Orientación Política  17432 non-null  object        \n",
      " 4   Autor                 8390 non-null   object        \n",
      " 5   Título                17425 non-null  object        \n",
      " 6   Medio                 2498 non-null   object        \n",
      " 7   Corpus                16690 non-null  object        \n",
      " 8   Producto              10353 non-null  object        \n",
      " 9   Enlace                17432 non-null  object        \n",
      " 10  CorpusPDF             237 non-null    object        \n",
      " 11  FechaPublicacion      17432 non-null  datetime64[ns]\n",
      " 12  Año                   17432 non-null  float64       \n",
      " 13  Mes                   17432 non-null  float64       \n",
      " 14  Dia                   17432 non-null  period[D]     \n",
      " 15  Texto                 17432 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(11), period[D](1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945d7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"Texto\"].dropna().apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f104b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_texts = df[\"tokens\"].tolist()\n",
    "global_dict = Dictionary(global_texts)\n",
    "global_dict.filter_extremes(no_below=5, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c1bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lda_model(texts, dictionary, corpus, min_topics=1, max_topics=2):\n",
    "    best_model, best_coh = None, -1\n",
    "    for k in range(min_topics, max_topics + 1):\n",
    "        lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, random_state=42)\n",
    "        coh = CoherenceModel(model=lda, texts=texts, dictionary=dictionary, coherence='c_v').get_coherence()\n",
    "        if coh > best_coh:\n",
    "            best_model, best_coh = lda, coh\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "321c29a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1797 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1122/1797 [7:47:19<4:22:27, 23.33s/it]c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n",
      "c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gensim\\models\\ldamodel.py:850: RuntimeWarning: overflow encountered in exp2\n",
      "  perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words\n",
      " 62%|██████▏   | 1122/1797 [7:47:43<4:41:22, 25.01s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'show_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(doc) == \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus): \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m      9\u001b[39m lda = best_lda_model(textos, global_dict, corpus)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, topic \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mlda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow_topics\u001b[49m(num_words=\u001b[32m3\u001b[39m, formatted=\u001b[38;5;28;01mFalse\u001b[39;00m)):\n\u001b[32m     11\u001b[39m     palabras = [w \u001b[38;5;28;01mfor\u001b[39;00m w,_ \u001b[38;5;129;01min\u001b[39;00m topic[\u001b[32m1\u001b[39m]]\n\u001b[32m     12\u001b[39m     vector = np.zeros(\u001b[38;5;28mlen\u001b[39m(global_dict))\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'show_topics'"
     ]
    }
   ],
   "source": [
    "topics_all = []\n",
    "\n",
    "for dia, grupo in tqdm(df.groupby(\"Dia\")):\n",
    "    textos = grupo[\"tokens\"].dropna().tolist()\n",
    "    if not textos: continue\n",
    "    corpus = [global_dict.doc2bow(text) for text in textos]\n",
    "    if all(len(doc) == 0 for doc in corpus): continue\n",
    "\n",
    "    lda = best_lda_model(textos, global_dict, corpus)\n",
    "    for idx, topic in enumerate(lda.show_topics(num_words=3, formatted=False)):\n",
    "        palabras = [w for w,_ in topic[1]]\n",
    "        vector = np.zeros(len(global_dict))\n",
    "        for w_id, prob in lda.get_topic_terms(idx, topn=len(global_dict)):\n",
    "            vector[w_id] = prob\n",
    "\n",
    "        peso = np.mean([prob[idx] for prob in lda.get_document_topics(corpus, minimum_probability=0)])\n",
    "        topics_all.append({\n",
    "            \"dia\": str(dia),\n",
    "            \"topico_id\": idx,\n",
    "            \"palabras\": \", \".join(palabras),\n",
    "            \"vector\": vector,\n",
    "            \"peso\": peso\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.DataFrame(topics_all)\n",
    "df_topics.to_parquet(\"lda_topics_day.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae11a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_thresholds(df_topics, thresholds):\n",
    "    elbows, sils = [], []\n",
    "    vecs = np.vstack(df_topics[\"vector\"].to_numpy())\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        G = nx.Graph()\n",
    "        for i, v in enumerate(vecs):\n",
    "            G.add_node(i)\n",
    "        for i in range(len(vecs)):\n",
    "            for j in range(i+1, len(vecs)):\n",
    "                sim = cosine_similarity([vecs[i]], [vecs[j]])[0][0]\n",
    "                if sim > thresh:\n",
    "                    G.add_edge(i, j)\n",
    "\n",
    "        if G.number_of_edges()==0:\n",
    "            elbows.append(0); sils.append(-1)\n",
    "            continue\n",
    "\n",
    "        part = community_louvain.best_partition(G)\n",
    "        labels = list(part.values())\n",
    "        elbows.append(len(set(labels)))\n",
    "        try:\n",
    "            sils.append(silhouette_score(vecs, labels))\n",
    "        except:\n",
    "            sils.append(-1)\n",
    "\n",
    "    return elbows, sils\n",
    "\n",
    "thresholds = np.linspace(0.4, 0.9, 10)\n",
    "elbows, sils = evaluar_thresholds(df_topics, thresholds)\n",
    "\n",
    "# Graficar resultados\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(thresholds, elbows, marker='o')\n",
    "plt.title(\"Elbow: # de clústeres vs threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"# clústeres\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(thresholds, sils, marker='o', color='purple')\n",
    "plt.title(\"Silhouette Score vs threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Silhouette\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_threshold = 0.75  # placeholder para definir manualmente\n",
    "similarity_threshold = manual_threshold\n",
    "\n",
    "# Construir grafo y agrupar\n",
    "G = nx.Graph()\n",
    "for i1, row1 in df_topics.iterrows():\n",
    "    for i2, row2 in df_topics.iterrows():\n",
    "        if i1>=i2: continue\n",
    "        if cosine_similarity([row1[\"vector\"]],[row2[\"vector\"]])[0][0] > similarity_threshold:\n",
    "            G.add_edge(i1, i2)\n",
    "partition = community_louvain.best_partition(G)\n",
    "df_topics[\"cluster\"] = df_topics.index.map(partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0016305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_topics.copy()\n",
    "df_plot[\"Fecha\"] = pd.to_datetime(df_plot[\"dia\"])\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x=\"Fecha\", y=\"peso\", color=\"cluster\",\n",
    "    hover_data=[\"palabras\"], title=\"Evolución diaria de tópicos emergentes\",\n",
    "    labels={\"peso\":\"Importancia\", \"Fecha\":\"Día\"}, template=\"plotly_white\"\n",
    ")\n",
    "fig.update_traces(marker=dict(size=8, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "fig.show()\n",
    "\n",
    "# Timeline\n",
    "timeline = df_topics.groupby([\"dia\", \"cluster\"])[\"peso\"].sum().reset_index()\n",
    "timeline[\"Fecha\"] = pd.to_datetime(timeline[\"dia\"])\n",
    "fig2 = px.line(\n",
    "    timeline, x=\"Fecha\", y=\"peso\", color=\"cluster\", markers=True,\n",
    "    title=\"Línea de tiempo diaria por clúster\", template=\"plotly_white\"\n",
    ")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def top_words(df, top_n=10):\n",
    "    cw = {}\n",
    "    for c in df[\"cluster\"].unique():\n",
    "        allwords = [w for txt in df[df[\"cluster\"]==c][\"palabras\"] for w in txt.split(\", \")]\n",
    "        cw[c] = [w for w,_ in Counter(allwords).most_common(top_n)]\n",
    "    return pd.DataFrame.from_dict(cw, orient=\"index\")\n",
    "\n",
    "hw = top_words(df_topics, top_n=10)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(pd.DataFrame([[1]*10]*len(hw), index=hw.index, columns=hw.columns),\n",
    "            annot=hw.values, fmt=\"\", cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Palabras por clúster\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
